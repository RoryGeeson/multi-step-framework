{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sobol_seq as sob\n",
    "from multi_step import multi_step_single_objective, utils\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "gpflow.config.set_default_float(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "plotGP = False\n",
    "useSavedModels = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def GPPlotter(stage, data, xdim, stageVar, stageOutputVar):\n",
    "    ## generate indices for sampling\n",
    "    xx = data.to_numpy(dtype=np.float32)[:,:xdim]\n",
    "    sortedInd = np.argsort(xx[:,stageVar])\n",
    "    ind = np.unique(np.random.randint(xx.shape[0], size=15))\n",
    "\n",
    "    ## obtain the test points for prediction\n",
    "    xx = xx[sortedInd[ind]]\n",
    "    yy = data.to_numpy(dtype=np.float32)[sortedInd[ind],xdim:]\n",
    "\n",
    "    ## predict mean and variance of latent GP at test points\n",
    "    try:\n",
    "        mean, var = stage.model.predict_f(Xnew=xx)\n",
    "    except:\n",
    "        xx = tf.convert_to_tensor(xx)\n",
    "        mean, var = stage.model.predict_f_compiled(Xnew=xx)\n",
    "\n",
    "    ## generate 10 samples from posterior\n",
    "    tf.random.set_seed(1)  # for reproducibility\n",
    "    try:\n",
    "        samples = stage.model.predict_f_samples(Xnew=xx, num_samples=10)\n",
    "    except:\n",
    "        samples = stage.model.predict_f_samples_compiled(Xnew=xx, num_samples=10)\n",
    "    # samples = samples\n",
    "\n",
    "    ## plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(xx[:,stageVar], yy[:,stageOutputVar], \"kx\", mew=2)\n",
    "    plt.plot(xx[:,stageVar], mean[:,stageOutputVar], \"C0\", lw=2)\n",
    "    plt.fill_between(\n",
    "        xx[:, stageVar],\n",
    "        mean[:, stageOutputVar] - 1.96 * np.sqrt(var[:, stageOutputVar]),\n",
    "        mean[:, stageOutputVar] + 1.96 * np.sqrt(var[:, stageOutputVar]),\n",
    "        color=\"C0\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    plt.plot(xx[:,stageVar], samples[:, :, stageOutputVar].numpy().T, \"C0\", linewidth=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Define the stage input ranges\n",
    "\n",
    "#'T','R','Ch2so4','a-pinene','3-carene','b-pinene','time'\n",
    "stage1Ranges = [[70,110],[0.15,0.35],[4,7],[0.4,0.8],[0,0.35],[0.05,0.4],[0.1,270]]\n",
    "#'a-terpinene','g-terpinene','terpinolene','T','Q_liq','Q_gas','radical_initiator','time'\n",
    "stage2Ranges = [[0,2],[0,2],[0,2],[80,150],[0.1,5],[5,120],[0,2],[0,240]]\n",
    "# 'out_11','out_12','out_13','out_14','out_2','ox','T'\n",
    "stage3Ranges = [[0,1],[0,3],[0,2],[0,2],[0,1],[0,21],[100,150]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def Stage_3(inputs):\n",
    "    out_3 = 71.05*(1-np.exp(-0.1657 * inputs[:,5]))*(1-np.exp(-0.2*(inputs[:,6]-100)))\n",
    "    out_4 = 1.04 * out_3/100 * ( (inputs[:,3] + inputs[:,4]/100 * (inputs[:,0]+inputs[:,1]+inputs[:,2])) )\n",
    "    return out_4\n",
    "\n",
    "def sobolSequenceConditions(condition_ranges, num_points):\n",
    "    \"\"\"\"\"\"\n",
    "    dimensions = len(condition_ranges)\n",
    "    sobol_sequence = sob.i4_sobol_generate(dimensions, num_points)\n",
    "    lower_bounds = np.array([condition[0] for condition in condition_ranges])\n",
    "    upper_bounds = np.array([condition[1] for condition in condition_ranges])\n",
    "    ranges = upper_bounds - lower_bounds\n",
    "    offset = np.tile(lower_bounds,(num_points,1))\n",
    "    conditions = sobol_sequence * ranges + offset\n",
    "    return np.array(conditions)\n",
    "\n",
    "# ('out_11','out_12','out_13','out_14','out_2','ox','T')\n",
    "stage_3_inputs = sobolSequenceConditions(stage3Ranges,20)\n",
    "stage_3_outputs = Stage_3(stage_3_inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "data_s1 = pd.read_csv('data/Stage_1.csv')\n",
    "data_s2 = pd.read_csv('data/Stage_2.csv')\n",
    "data_s3 = pd.DataFrame(np.concatenate((stage_3_inputs,np.expand_dims(stage_3_outputs,1)),axis=1),\n",
    "          columns=['out_11','out_12','out_13','out_14','out_2','ox','T','out_3'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def fit_stage(data, inputHeaders, outputHeaders):\n",
    "    X = data[inputHeaders]\n",
    "    Y = data[outputHeaders]\n",
    "    kernel = gpflow.kernels.Matern52()\n",
    "    gp = gpflow.models.GPR(data=(X,Y), kernel=kernel)\n",
    "    # gpflow.utilities.print_summary(gp)\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    optLogs = opt.minimize(gp.training_loss, gp.trainable_variables, options=dict(maxiter=1000))\n",
    "    return gp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Fit the stages\n",
    "if not useSavedModels:\n",
    "    data_s1 = data_s1[['T','R','Ch2so4','a-pinene','3-carene','b-pinene','time','alpha-terpinene-output',\n",
    "                       'gamma-terpinene-output','terpinolene-output','p-cymene-output']]\n",
    "    stage1Model = fit_stage(data_s1, inputHeaders=['T','R','Ch2so4','a-pinene','3-carene','b-pinene','time'],\n",
    "                            outputHeaders=['alpha-terpinene-output','gamma-terpinene-output','terpinolene-output','p-cymene-output'])\n",
    "    data_s2 = data_s2[['a-terpinene','g-terpinene','terpinolene','T','Q_liq','Q_gas','radical_initiator','time','Y2']]\n",
    "    stage2Model = fit_stage(data_s2, inputHeaders=['a-terpinene','g-terpinene','terpinolene','T','Q_liq','Q_gas','radical_initiator','time'],\n",
    "                            outputHeaders=['Y2'])\n",
    "    data_s3 = data_s3[['out_11','out_12','out_13','out_14','out_2','ox','T','out_3']]\n",
    "    stage3Model = fit_stage(data_s3, inputHeaders=['out_11','out_12','out_13','out_14','out_2','ox','T'],\n",
    "                            outputHeaders=['out_3'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Save the models\n",
    "\n",
    "# if not useSavedModels:\n",
    "#     stage1Model.predict_f_compiled = tf.function(stage1Model.predict_f, input_signature=[tf.TensorSpec(shape=[None, 7], dtype=tf.float32)])\n",
    "#     # stage1Model.predict_f_samples_compiled = tf.function(stage1Model.predict_f_samples,\n",
    "#     #                                                      input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool)])\n",
    "#     stage1Model.predict_f_samples_compiled = tf.function(stage1Model.predict_f_samples)\n",
    "#     stage2Model.predict_f_compiled = tf.function(stage2Model.predict_f, input_signature=[tf.TensorSpec(shape=[None, 8], dtype=tf.float32)])\n",
    "#     # stage2Model.predict_f_samples_compiled = tf.function(stage2Model.predict_f_samples, input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool)])\n",
    "#     stage2Model.predict_f_samples_compiled = tf.function(stage2Model.predict_f_samples)\n",
    "#     stage3Model.predict_f_compiled = tf.function(stage3Model.predict_f, input_signature=[tf.TensorSpec(shape=[None, 7], dtype=tf.float32)])\n",
    "#     # stage3Model.predict_f_samples_compiled = tf.function(stage3Model.predict_f_samples, input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.float32),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool),\n",
    "#     #                                                                       tf.TensorSpec(shape=1, dtype=tf.bool)])\n",
    "#     stage3Model.predict_f_samples_compiled = tf.function(stage3Model.predict_f_samples)\n",
    "#\n",
    "#     save_dir = './GPModels/'\n",
    "#     tf.saved_model.save(stage1Model, save_dir+'Model1/')\n",
    "#     tf.saved_model.save(stage2Model, save_dir+'Model2/')\n",
    "#     tf.saved_model.save(stage3Model, save_dir+'Model3/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "\n",
    "save_dir = './GPModels/'\n",
    "if useSavedModels:\n",
    "    stage1Model = tf.saved_model.load(save_dir+'Model1/')\n",
    "    stage2Model = tf.saved_model.load(save_dir+'Model2/')\n",
    "    stage3Model = tf.saved_model.load(save_dir+'Model3/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Generate the multi_step class\n",
    "multi_step_graph = multi_step_single_objective.multi_step_output_prediction('adagrad', learning_rate=0.005, training='sobol')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Load the models into the framework\n",
    "\n",
    "#Define the stages\n",
    "# stageID, stageModel, conditionRanges, followingStages (followingStageID, feedingVariables)\n",
    "stage1 = utils.stage(0, stage1Model, stage1Ranges, outputDimension=9, followingStages=[[1, [0,1,2]], [2, [0,1,2,3]]])\n",
    "stage2 = utils.stage(1, stage2Model, stage2Ranges[3:], outputDimension=1, followingStages=[[2,[0]]])\n",
    "stage3 = utils.stage(2, stage3Model, stage3Ranges[5:], outputDimension=1)\n",
    "\n",
    "stages = [stage1, stage2, stage3]\n",
    "\n",
    "multi_step_graph.loadModels(stages)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "if plotGP == True:\n",
    "    # print('Stage 1')\n",
    "    # GPPlotter(stage1,data_s1,7,2,0)\n",
    "    # # GPPlotter(stage2,data_s2,8,0,0)\n",
    "    # print('Stage 3')\n",
    "    # GPPlotter(stage3,data_s3,7,5,0)\n",
    "    # print('Stage 2')\n",
    "    # for i in range(8):\n",
    "    #     GPPlotter(stage2,data_s2,8,i,0)\n",
    "    print('Stage 3')\n",
    "    for i in range(7):\n",
    "        GPPlotter(stage3,data_s3,7,i,0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Define the objective functions\n",
    "\n",
    "def objectiveFunction1(var1):\n",
    "    return var1 * 10\n",
    "\n",
    "def objectiveFunction2(*args):\n",
    "    # stage1: 'T','R','Ch2so4','a-pinene','3-carene','b-pinene','time'\n",
    "    # stage2: 'T','Q_liq','Q_gas','radical_initiator','time'\n",
    "    # stage3: 'ox','T'\n",
    "\n",
    "    materialUnitCosts = tf.constant([1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "    materialIndices = [2,3,4,5,10,12]\n",
    "    timeCostConstant = 0.1\n",
    "    heatingCostConstant = 0.1\n",
    "\n",
    "    # materialAmounts = tf.concat([*args[2:6],args[10],args[12]], axis=0)\n",
    "    # materialAmounts = tf.constant(args[2:6]+[args[10]]+[args[12]])\n",
    "\n",
    "    # materialCosts = tf.tensordot(materialAmounts, materialUnitCosts, axes=1)\n",
    "    # materialCosts = tf.reduce_sum(materialAmounts)\n",
    "    for count, index in enumerate(materialIndices):\n",
    "        try:\n",
    "            materialCosts += materialUnitCosts[count] * args[index]\n",
    "        except:\n",
    "            materialCosts = materialUnitCosts[index] * args[index]\n",
    "    timeCosts = (args[6] + args[11]) * timeCostConstant\n",
    "    heatingCosts = (args[0] + args[7] + args[13]) * heatingCostConstant\n",
    "    # print('Time: {}, Heat: {}, Materials: {}'.format(timeCosts,heatingCosts,materialCosts))\n",
    "    return -(timeCosts + heatingCosts + materialCosts)\n",
    "\n",
    "def objectiveFunction(*args):\n",
    "    return objectiveFunction1(args[0]) - objectiveFunction2(*args[1:])\n",
    "\n",
    "# Define the objective objects including the objective functions and the IDs of relevant variables/outputs\n",
    "# Define objective variables with form: [stage, 'input'/'output', stage variable]\n",
    "# objective1 = utils.objective(objectiveFunction1, [[stage3,'outputs',0]])\n",
    "# objective2 = utils.objective(objectiveFunction2,[\n",
    "#     [stage1,'inputs',0],[stage1,'inputs',1],[stage1,'inputs',2],[stage1,'inputs',3],[stage1,'inputs',4],[stage1,'inputs',5],[stage1,'inputs',6],\n",
    "#     [stage2,'inputs',3],[stage2,'inputs',4],[stage2,'inputs',5],[stage2,'inputs',6],[stage2,'inputs',7],\n",
    "#     [stage3,'inputs',5],[stage3,'inputs',6]\n",
    "# ])\n",
    "objective0 = utils.objective(objectiveFunction,[\n",
    "    [stage3,'outputs',0],\n",
    "    [stage1,'inputs',0],[stage1,'inputs',1],[stage1,'inputs',2],[stage1,'inputs',3],[stage1,'inputs',4],[stage1,'inputs',5],[stage1,'inputs',6],\n",
    "    [stage2,'inputs',3],[stage2,'inputs',4],[stage2,'inputs',5],[stage2,'inputs',6],[stage2,'inputs',7],\n",
    "    [stage3,'inputs',5],[stage3,'inputs',6]\n",
    "])\n",
    "\n",
    "# objectives = [objective1, objective2]\n",
    "objectives = [objective0]\n",
    "# objectives = [objective1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Define the objectives for the framework\n",
    "multi_step_graph.defineObjectives(objectives)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "77.10458\n",
      "[ 87.57407   84.87688   68.889626  87.02397   75.88355   66.83063\n",
      "  75.575096  89.31254   77.608955  76.622375  80.95446   72.372574\n",
      "  78.841354  76.67275   60.39403   56.236305  94.413765 101.8533\n",
      "  60.644005  76.14494   93.40366   78.6439    55.125347  66.71939\n",
      "  79.728035  89.937675  70.49658   57.69725   96.15269   76.50777 ]\n",
      "Epoch: 0, Loss: inf\n",
      "Epoch: 1, Loss: nan\n",
      "Epoch: 2, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-32-3470786967cd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Train\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# numStartSamples, epochs=5, h_dim=5, n_layers=4, network_type='GATConv', **kwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mmean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlosses\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmulti_step_graph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m25\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_layers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnetwork_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'GATConv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_heads\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#, activation=tf.keras.activations.relu)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - University of Cambridge\\Year_1\\Pietro\\multi-step-framework\\multi_step\\multi_step_single_objective.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, numStartSamples, epochs, h_dim, n_layers, network_type, **kwargs)\u001B[0m\n\u001B[0;32m    605\u001B[0m         \u001B[0mlosses\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    606\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 607\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrainableVariables\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactualObjectiveValues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    608\u001B[0m             \u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Epoch: {}, Loss: {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - University of Cambridge\\Year_1\\Pietro\\multi-step-framework\\multi_step\\multi_step_single_objective.py\u001B[0m in \u001B[0;36mepoch\u001B[1;34m(self, inputs, trainableVariables, objectiveValues)\u001B[0m\n\u001B[0;32m    561\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0minputDict\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massignInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputDict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 563\u001B[1;33m                 \u001B[0mobjectivePred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgivenInputLoop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;31m#objectiveValue,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    564\u001B[0m                 \u001B[1;31m# print('objectivePred: ', objectivePred)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    565\u001B[0m                 \u001B[1;31m# objectiveValues = tf.concat([objectiveValues,tf.convert_to_tensor(list(objectiveValue.values()))], axis=1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - University of Cambridge\\Year_1\\Pietro\\multi-step-framework\\multi_step\\multi_step_single_objective.py\u001B[0m in \u001B[0;36mgivenInputLoop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    542\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mstageID\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageGraph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageIDs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m             stuff = tf.reshape(\n\u001B[1;32m--> 544\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageGraph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageEncoders\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstageID\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageGraph\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstageInputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstageID\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    545\u001B[0m                 [1, self.h_dim])\n\u001B[0;32m    546\u001B[0m             \u001B[0mh_inputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mh_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstuff\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1028\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1029\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1030\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1031\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1032\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - University of Cambridge\\Year_1\\Pietro\\multi-step-framework\\multi_step\\models.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoderNet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1028\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1029\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1030\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1031\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1032\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    378\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuilt\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_init_graph_network\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 380\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSequential\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    381\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m  \u001B[1;31m# handle the corner case where self.layers is empty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    418\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    419\u001B[0m     \"\"\"\n\u001B[1;32m--> 420\u001B[1;33m     return self._run_internal_graph(\n\u001B[0m\u001B[0;32m    421\u001B[0m         inputs, training=training, mask=mask)\n\u001B[0;32m    422\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    554\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    555\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 556\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    557\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    558\u001B[0m         \u001B[1;31m# Update tensor_dict.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1028\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[0;32m   1029\u001B[0m             self._compute_dtype_object):\n\u001B[1;32m-> 1030\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1031\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1032\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   1251\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1252\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muse_bias\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1253\u001B[1;33m       \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias_add\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1254\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1255\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mactivation\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    205\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 206\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    207\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    208\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001B[0m in \u001B[0;36mbias_add\u001B[1;34m(value, bias, data_format, name)\u001B[0m\n\u001B[0;32m   3375\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3376\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3377\u001B[1;33m       return gen_nn_ops.bias_add(\n\u001B[0m\u001B[0;32m   3378\u001B[0m           value, bias, data_format=data_format, name=name)\n\u001B[0;32m   3379\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\geeso\\virtualenvironments\\multi-step-framework\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001B[0m in \u001B[0;36mbias_add\u001B[1;34m(value, bias, data_format, name)\u001B[0m\n\u001B[0;32m    671\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 673\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m    674\u001B[0m         _ctx, \"BiasAdd\", name, value, bias, \"data_format\", data_format)\n\u001B[0;32m    675\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# numStartSamples, epochs=5, h_dim=5, n_layers=4, network_type='GATConv', **kwargs\n",
    "mean, losses = multi_step_graph.train(30, epochs=100, h_dim=25, n_layers=1, network_type='GATConv', num_heads=2)#, activation=tf.keras.activations.relu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Actual, predicted = multi_step_graph.get_results(30, mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(Actual)\n",
    "print(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pareto = plt.figure(figsize=(12, 6))\n",
    "ax = pareto.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.scatter(Actual,predicted)\n",
    "# ax.set_xscale('log')\n",
    "ax.set_xlabel('Actual Objective Value')\n",
    "ax.set_ylabel('Predicted Objective Value')\n",
    "pareto.savefig('././figures/predicted.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fig = plt.figure(figsize=(12, 6))\n",
    "ax = loss_fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.scatter(range(len(losses)),losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "loss_fig.savefig('././figures/losses.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}